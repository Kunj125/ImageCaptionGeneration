{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f32a1b6e-bce8-4bd8-bef9-e70fd244cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as plp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "from torch.utils.data import Dataset\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "993b8401-17d2-4a7b-848c-418c2d0e6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, root, ann_file, transform=None):\n",
    "        self.root = root\n",
    "        ann_file_dir = os.path.join(self.root, ann_file)\n",
    "        self.labels = pd.read_csv(ann_file_dir, sep='|')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root, \"images\", self.labels.iloc[idx, 0])\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Get all the labels of the corresponding image\n",
    "        labels = []\n",
    "        start_id = idx - (idx % 5) \n",
    "        for i in range(start_id, start_id + 5):\n",
    "            labels.append(self.labels.iloc[i, 2])\n",
    "\n",
    "        # Just get the corresponding label\n",
    "        # labels = self.labels.iloc[idx, 2]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e39be152-148c-4dfd-85bc-a7760812e559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(((0.444, 0.421, 0.385)), (0.285, 0.277, 0.286))\n",
    "])\n",
    "data = Dataset(root = \"data\", ann_file = \"results.csv\", transform = preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "920e0929-1822-42c7-bde2-3bf654403e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8088, 0.8638, 0.8776,  ..., 0.8638, 0.8226, 0.7675],\n",
      "         [0.9189, 0.9189, 0.8638,  ..., 1.0427, 0.9877, 0.9602],\n",
      "         [0.9602, 0.9051, 0.8914,  ..., 1.1115, 1.0565, 1.0290],\n",
      "         ...,\n",
      "         [1.0702, 1.0702, 1.0427,  ..., 1.0565, 0.9739, 0.8776],\n",
      "         [0.9464, 1.0152, 1.0427,  ..., 1.1253, 1.0290, 0.9602],\n",
      "         [0.8501, 0.8638, 0.9051,  ..., 1.0152, 1.0565, 1.0152]],\n",
      "\n",
      "        [[0.9577, 1.0285, 1.0426,  ..., 0.9718, 0.9152, 0.8727],\n",
      "         [1.0285, 1.0426, 1.0001,  ..., 1.1417, 1.0709, 1.0426],\n",
      "         [1.0851, 1.0426, 1.0285,  ..., 1.1983, 1.1134, 1.0709],\n",
      "         ...,\n",
      "         [1.1700, 1.1700, 1.1417,  ..., 1.1134, 1.0001, 0.9010],\n",
      "         [1.0285, 1.0992, 1.1417,  ..., 1.1842, 1.1276, 1.0568],\n",
      "         [0.9152, 0.9152, 0.9860,  ..., 1.0992, 1.1417, 1.0851]],\n",
      "\n",
      "        [[0.7517, 0.8203, 0.8340,  ..., 0.7380, 0.7106, 0.6832],\n",
      "         [0.8477, 0.8477, 0.8066,  ..., 0.9300, 0.8614, 0.8340],\n",
      "         [0.8889, 0.8340, 0.8340,  ..., 0.9986, 0.9437, 0.8889],\n",
      "         ...,\n",
      "         [0.9574, 0.9574, 0.9574,  ..., 0.8752, 0.7929, 0.6832],\n",
      "         [0.8477, 0.9300, 0.9574,  ..., 0.9848, 0.9026, 0.8066],\n",
      "         [0.7380, 0.7655, 0.8066,  ..., 0.9300, 0.9437, 0.8614]]])\n",
      " A white and black dog and a brown dog in sandy terrain .\n",
      " Two large dogs chasing each other at the beach .\n",
      " The two large dogs are running through sand .\n",
      " One dog is chasing another one on the beach .\n",
      " A woolly dog chases a Doberman on a beach .\n"
     ]
    }
   ],
   "source": [
    "# nth image and its captions\n",
    "n = 1000\n",
    "print(data[n][0])\n",
    "for caption in data[n][1]:\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b836d82-1299-47cd-981b-d2f772ecac50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
